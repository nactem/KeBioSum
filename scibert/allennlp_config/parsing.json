{
    "random_seed":  std.parseInt(std.extVar("SEED")),
    "pytorch_seed": std.parseInt(std.extVar("PYTORCH_SEED")),
    "numpy_seed": std.parseInt(std.extVar("NUMPY_SEED")),
    "dataset_reader": {
        "type": "universal_dependencies",
        "token_indexers": {
          "bert": {
              "type": "bert-pretrained",
              "pretrained_model": std.extVar("BERT_VOCAB"),
              "do_lowercase": std.extVar("IS_LOWERCASE"),
              "use_starting_offsets": true
          }
        }
    },
    "train_data_path": std.extVar("TRAIN_PATH"),
    "validation_data_path": std.extVar("DEV_PATH"),
    "test_data_path": std.extVar("TEST_PATH"),
    "evaluate_on_test": true,
    "model": {
        "type": "biaffine_parser",
        "arc_representation_dim": 400,
        "dropout": 0.5,
        "input_dropout": 0.5,
        "tag_representation_dim": 400,
        "text_field_embedder": {
            "allow_unmatched_keys": true,
            "embedder_to_indexer_map": {
                "bert": ["bert", "bert-offsets"]
            },
            "token_embedders": {
                "bert": {
                    "type": "bert-pretrained",
                    "pretrained_model": std.extVar("BERT_WEIGHTS")
                }
            }
        },
        "use_mst_decoding_for_validation": false,
        "encoder": {
            "type": "stacked_bidirectional_lstm",
            "hidden_size": 400,
            "input_size": 768,
            "num_layers": 2,
            "recurrent_dropout_probability": 0.5,
            "use_highway": false
        }
    },
  "iterator": {
    "type": "bucket",
    "sorting_keys": [["words", "num_tokens"]],
    "batch_size": std.parseInt(std.extVar("GRAD_ACCUM_BATCH_SIZE")) / 2,
    "cache_instances": true
   },
  "trainer": {
    "optimizer": {
        "type": "bert_adam",
        "lr": std.extVar("LEARNING_RATE")
    },
    "validation_metric": "+LAS",
    "num_serialized_models_to_keep": 3,
    "num_epochs": std.parseInt(std.extVar("NUM_EPOCHS")),
    "should_log_learning_rate": true,
//    "learning_rate_scheduler": {
//      "type": "slanted_triangular",
//      "num_epochs": std.parseInt(std.extVar("NUM_EPOCHS")),
//      "num_steps_per_epoch": std.parseInt(std.extVar("DATASET_SIZE")) / std.parseInt(std.extVar("GRAD_ACCUM_BATCH_SIZE"))
//    },
    "gradient_accumulation_batch_size": std.parseInt(std.extVar("GRAD_ACCUM_BATCH_SIZE")),
    "patience": 10,
    "cuda_device": std.parseInt(std.extVar("CUDA_DEVICE"))
  }
}